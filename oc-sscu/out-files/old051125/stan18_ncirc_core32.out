------------------------------------------------------
Job is running on node ------------------------------------------------------
SLURM: qsub is running on headnode2
SLURM: originating queue is core32
SLURM: executing queue is core32
SLURM: working directory is /beegfs/car/bxster25/oc-sscu
SLURM: job identifier is 22726
SLURM: job name is stan18_ncirc_core32
SLURM: node file is node064
SLURM: current home directory is /home2/bxster25
SLURM: PATH = /usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/local/sbin:/usr/share/Modules/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin
------------------------------------------------------
Usage: Rscript [options] file [args]
   or: Rscript [options] -e expr [-e expr2 ...] [args]
A binary front-end to R, for use in scripting applications.

Options:
  --help              Print usage and exit
  --version           Print version and exit
  --verbose           Print information on progress
  --default-packages=LIST  Attach these packages on startup;
                        a comma-separated LIST of package names, or 'NULL'
and options to R (in addition to --no-echo --no-restore), for example:
  --save              Do save workspace at the end of the session
  --no-environ        Don't read the site and user environment files
  --no-site-file      Don't read the site-wide Rprofile
  --no-init-file      Don't read the user R profile
  --restore           Do restore previously saved objects at startup
  --vanilla           Combine --no-save, --no-restore, --no-site-file,
                        --no-init-file and --no-environ

Expressions (one or more '-e <expr>') may be used *instead* of 'file'.
Any additional 'args' can be accessed from R via 'commandArgs(TRUE)'.
See also  ?Rscript  from within R.
/soft/R-4.4.2/bin/Rscript

SAMPLING
 FOR MODEL 'anon_modelSAMPLING' NOW (CHAIN  FOR MODEL '3).
anon_model' NOW (CHAIN 2).

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 1: 
Chain 1: Gradient evaluation took 0.011182 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 111.82 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1Chain : 
2: Chain 1
Chain : 
2: Gradient evaluation took 0.011295 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 112.95 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 4: 
Chain 4: Gradient evaluation took 0.021588 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 215.88 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 3: 
Chain 3: Gradient evaluation took 0.011114 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 111.14 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 2: Iteration:     1 / 12000 [  0%]  (Warmup)
Chain 4: Iteration:     1 / 12000 [  0%]  (Warmup)
Chain 1: Iteration:     1 / 12000 [  0%]  (Warmup)
Chain 3: Iteration:     1 / 12000 [  0%]  (Warmup)
Chain 4: Iteration:  1200 / 12000 [ 10%]  (Warmup)
Chain 4: Iteration:  2400 / 12000 [ 20%]  (Warmup)
Chain 4: Chain Iteration:  3600 / 12000 [ 30%]  (Warmup)Chain 23
: Iteration:  1200 / 12000 [ 10%]  (Warmup): 
Iteration:  1200 / 12000 [ 10%]  (Warmup)
Chain 4: Iteration:  4800 / 12000 [ 40%]  (Warmup)
Chain 3: Iteration:  2400 / 12000 [ 20%]  (Warmup)
Chain 2: Iteration:  2400 / 12000 [ 20%]  (Warmup)
Chain 4: Iteration:  6000 / 12000 [ 50%]  (Warmup)
Chain 4: Iteration:  6001 / 12000 [ 50%]  (Sampling)
Chain 3: Iteration:  3600 / 12000 [ 30%]  (Warmup)
Chain 2: Iteration:  3600 / 12000 [ 30%]  (Warmup)
Chain 3: Iteration:  4800 / 12000 [ 40%]  (Warmup)
Chain 2: Iteration:  4800 / 12000 [ 40%]  (Warmup)
Chain 4: Iteration:  7200 / 12000 [ 60%]  (Sampling)
Chain 3: Iteration:  6000 / 12000 [ 50%]  (Warmup)
Chain 3: Iteration:  6001 / 12000 [ 50%]  (Sampling)
Chain 2: Iteration:  6000 / 12000 [ 50%]  (Warmup)
Chain 2: Iteration:  6001 / 12000 [ 50%]  (Sampling)
Chain 3: Iteration:  7200 / 12000 [ 60%]  (Sampling)
Chain 2: Iteration:  7200 / 12000 [ 60%]  (Sampling)
Chain 4: Iteration:  8400 / 12000 [ 70%]  (Sampling)
Chain 3: Iteration:  8400 / 12000 [ 70%]  (Sampling)
Chain 2: Iteration:  8400 / 12000 [ 70%]  (Sampling)
Chain 3: Iteration:  9600 / 12000 [ 80%]  (Sampling)
Chain 1: Iteration:  1200 / 12000 [ 10%]  (Warmup)
Chain 2: Iteration:  9600 / 12000 [ 80%]  (Sampling)
Chain 4: Iteration:  9600 / 12000 [ 80%]  (Sampling)
Chain 3: Iteration: 10800 / 12000 [ 90%]  (Sampling)
Chain 2: Iteration: 10800 / 12000 [ 90%]  (Sampling)
Chain 3: Iteration: 12000 / 12000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 42346.8 seconds (Warm-up)
Chain 3:                24105 seconds (Sampling)
Chain 3:                66451.8 seconds (Total)
Chain 3: 
Chain 2: Iteration: 12000 / 12000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 44768.4 seconds (Warm-up)
Chain 2:                23655.7 seconds (Sampling)
Chain 2:                68424.1 seconds (Total)
Chain 2: 
Chain 4: Iteration: 10800 / 12000 [ 90%]  (Sampling)
Chain 4: Iteration: 12000 / 12000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 32287 seconds (Warm-up)
Chain 4:                47872.1 seconds (Sampling)
Chain 4:                80159 seconds (Total)
Chain 4: 
Chain 1: Iteration:  2400 / 12000 [ 20%]  (Warmup)
Chain 1: Iteration:  3600 / 12000 [ 30%]  (Warmup)
Chain 1: Iteration:  4800 / 12000 [ 40%]  (Warmup)
Chain 1: Iteration:  6000 / 12000 [ 50%]  (Warmup)
Chain 1: Iteration:  6001 / 12000 [ 50%]  (Sampling)
Chain 1: Iteration:  7200 / 12000 [ 60%]  (Sampling)
Chain 1: Iteration:  8400 / 12000 [ 70%]  (Sampling)
Chain 1: Iteration:  9600 / 12000 [ 80%]  (Sampling)
Chain 1: Iteration: 10800 / 12000 [ 90%]  (Sampling)
Chain 1: Iteration: 12000 / 12000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 199553 seconds (Warm-up)
Chain 1:                302240 seconds (Sampling)
Chain 1:                501794 seconds (Total)
Chain 1: 
Time difference of 5.813671 days
Sample size: 3665 
Inference for Stan model: anon_model.
4 chains, each with iter=12000; warmup=6000; thin=1; 
post-warmup draws per chain=6000, total post-warmup draws=24000.

       mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
A     15.42    0.04 0.18  15.06  15.30  15.42  15.55  15.78    19 1.10
B    -14.20    0.02 0.14 -14.47 -14.29 -14.20 -14.10 -13.93    35 1.07
C      2.97    0.04 0.22   2.53   2.82   2.97   3.12   3.39    25 1.09
K      8.44    0.12 1.00   6.44   7.78   8.44   9.14  10.36    68 1.08
u0     9.33    0.04 0.15   9.04   9.23   9.34   9.44   9.61    16 1.13
v0    11.21    0.02 0.16  10.91  11.10  11.20  11.32  11.53    68 1.07
w0     7.15    0.02 0.07   7.01   7.10   7.15   7.20   7.31    10 1.21
s_l    4.49    0.05 0.12   4.25   4.41   4.49   4.58   4.73     6 1.23
s_b    2.87    0.04 0.08   2.70   2.81   2.87   2.93   3.03     6 1.22
nu_l   1.88    0.07 0.12   1.65   1.79   1.89   1.96   2.09     3 1.71
nu_b   2.03    0.08 0.14   1.76   1.93   2.04   2.13   2.27     3 1.56

Samples were drawn using NUTS(diag_e) at Mon Oct 27 07:59:09 2025.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
null device 
          1 
A <- 15.4226 
B <- -14.19733 
C <- 2.966562 
K <- 8.440224 
u0 <- 9.332791 
v0 <- 11.20737 
w0 <- 7.153329 
s_l <- 4.492027 
s_b <- 2.868715 
nu_l <- 1.875852 
nu_b <- 2.030308 
scale t dist mul: 4.492 
scale t dist mub: 2.869 
------------------------------------------------------
Job ends
